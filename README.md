# webscraping-challenge
MSU Data Analytics BootCamp Module 11 Challenge

Code files: part_1_mars_news_complete.ipynb and part_2_mars_weather_complete.ipynb

This repository contains two core files: 1. a Jupyter Notebook based processing of news website that was directly scraped from the internet using a combination of the Splinter and BeautifulSoup Python libraries,  and 2. a pandas-centric Jupyter Notebook analysis of a similarly scraped wesbite which contains a table of data about the weather on Mars. From the news wesbite, every article title and article preview text is automatically located, stored, and then exported to a JSON file. From the Mars weather website, the data table is automatically scraped and convered into a pandas DataFrame from which a series of simple analyses of the scraped data is performed.

*Code sourcing statement*
-----------------------

I did use a natural language description of the desired code's functions entered into ChatGPT 3.5 to help with syntax. I did copy pieces of that code in order to be more efficient, but I tailored it to fit all of the desired functions of this paricular project. I did not directly copy and paste any of this code from the internet otherwise (e.g., from StackExchange or any other webpage). I did not seek any assistance or use code written by my peers or instructors for this challenge.

End of code sourcing statement.

 ----------------------

 The repository also contains the output files generated by the code in a directory called 'output' inside the repository.
